save_loc: "/glade/work/$USER/repos/global/miles-credit/results/test_configs"
seed: 1000

data:
    variables: ['U','V','T','Q']
    surface_variables: ['SP','t2m','V500','U500','T500','Z500','Q500']
    #save_loc: '/glade/derecho/scratch/schreck/STAGING/TOTAL_*'
    #train_test_split: [ 0.5, 0.25, 0.25 ]
    #train_years: None
    #valid_years: None
    #test_years: None
    save_loc: '/glade/campaign/cisl/aiml/wchapman/MLWPS/STAGING/ONE*.zarr'
    mean_path: '/glade/derecho/scratch/schreck/STAGING/All_2010_staged.mean.Lev.SLO.nc'
    std_path: '/glade/derecho/scratch/schreck/STAGING/All_2010_staged.std.Lev.SLO.nc'
    history_len: 1
    forecast_len: 0
    valid_history_len: 1
    valid_forecast_len: 0
    time_step: 1
    
trainer:
    mode: none # none, ddp, fsdp
    train_batch_size: 10
    valid_batch_size: 10
    batches_per_epoch: 0 # Set to 0 to use len(dataloader)
    valid_batches_per_epoch: 100
    learning_rate: 5.0e-04
    weight_decay: 1.0e-05
    start_epoch: 0
    epochs: 100
    amp: False
    grad_accum_every: 1
    grad_max_norm: 1.0
    thread_workers: 0
    valid_thread_workers: 0
    stopping_patience: 100
    teacher_forcing_ratio: 0.0
    stop_rollout: 0.9
    load_weights: False
    load_optimizer: False
    use_scheduler: True
    # scheduler:
    #     scheduler_type: cosine-annealing
    #     first_cycle_steps: 500
    #     cycle_mult: 6.0
    #     max_lr: 5.0e-04
    #     min_lr: 5.0e-07
    #     warmup_steps: 499
    #     gamma: 0.7
    scheduler:
        scheduler_type: lambda
  
model:
    type: "rvt"
    channels: 4
    depth: 4
    static_variables: {
        "cos_lat": "/glade/u/home/wchapman/MLWPS/DataLoader/static_variables_ERA5_zhght_onedeg.nc" #"/glade/u/home/wchapman/MLWPS/DataLoader/static_variables_ERA5_zhght.nc"
    }
    dim: 1024
    dim_head: 1024
    dropout: 0.0
    frame_patch_size: 3
    frames: 15
    heads: 8
    image_height: 192
    image_width: 288
    mlp_dim: 1024
    patch_height: 16
    patch_width: 16
    rk4_integration: false
    surface_channels: 7
    token_dropout: 0.0
    use_rotary: True
    use_ds_conv: True
    use_glu: True
    use_decoder_conv_layers: false
    use_cls_tokens: true
    use_codebook: false
    vq_codebook_dim: 768
    vq_codebook_size: 512
    vq_commitment_weight: 0.8265613175117377
    vq_decay: 0.059685615129391856
    vq_kmeans_init: true
    vq_use_cosine_sim: true
    transformer_type: "lucidrains"  # choose between pytorch or lucidrains
    
loss: 
    training_loss: "mse"
    use_vgg: False
    use_power_loss: True # use either power or spectral loss
    use_spectral_loss: False
    spectral_wavenum_init: 20
    spectral_lambda_reg: 0.1 # power loss is order of 1e1 (usually between 1-10)
    use_latitude_weights: True
    latitude_weights: "/glade/u/home/wchapman/MLWPS/DataLoader/static_variables_ERA5_zhght_onedeg.nc" #"/glade/u/home/wchapman/MLWPS/DataLoader/static_variables_ERA5_zhght.nc"
    use_variable_weights: False
    variable_weights:
        U: [0.132, 0.123, 0.113, 0.104, 0.095, 0.085, 0.076, 0.067, 0.057, 0.048, 0.039, 0.029, 0.02 , 0.011, 0.005]
        V: [0.132, 0.123, 0.113, 0.104, 0.095, 0.085, 0.076, 0.067, 0.057, 0.048, 0.039, 0.029, 0.02 , 0.011, 0.005]
        T: [0.132, 0.123, 0.113, 0.104, 0.095, 0.085, 0.076, 0.067, 0.057, 0.048, 0.039, 0.029, 0.02 , 0.011, 0.005]
        Q: [0.132, 0.123, 0.113, 0.104, 0.095, 0.085, 0.076, 0.067, 0.057, 0.048, 0.039, 0.029, 0.02 , 0.011, 0.005]
        SP: 0.1
        t2m: 1.0
        V500: 0.1
        U500: 0.1
        T500: 0.1
        Z500: 0.1
        Q500: 0.1

predict:
    forecasts: [
        ["1989-12-31 00:00:00", "1990-01-02 00:00:00"],
        ["2018-06-01 00:00:00", "2018-06-07 00:00:00"]
    ]

pbs: #derecho
    conda: "holodec"
    project: "NAML0001"
    job_name: "rvt-multi"
    walltime: "12:00:00"
    nodes: 8
    ncpus: 64
    ngpus: 4
    mem: '480GB'
    queue: 'main'
    #queue: 'preempt'
    
# pbs: # casper
#     conda: "/glade/work/schreck/miniconda3/envs/evidential"
#     job_name: 'latlon'
#     nodes: 1
#     ncpus: 8
#     ngpus: 1
#     mem: '128GB'
#     walltime: '12:00:00'
#     gpu_type: 'a100'
#     cpu_type: 'milan'
#     project: 'NAML0001'
#     queue: 'casper'
