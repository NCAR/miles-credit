import torch
import torch.nn as nn
import torch.nn.functional as F
import xarray as xr
import numpy as np
import logging
import warnings
from credit.loss import *
del latitude_weights, variable_weights, VariableTotalLoss2D

logger = logging.getLogger(__name__)


# todo: update me
# def variable_weights(conf, channels, frames):
#     """Create variable-specific weights for different atmospheric
#     and surface channels.
# 
#     This function loads weights for different atmospheric variables
#     (e.g., U, V, T, Q) and surface variables (e.g., SP, t2m) from
#     the configuration file. It then combines them into a single
#     weight tensor for use in loss calculations.
# 
#     Args:
#         conf (dict): Configuration dictionary containing the
#             variable weights.
#         channels (int): Number of channels for atmospheric variables.
#         frames (int): Number of time frames.
# 
#     Returns:
#         torch.Tensor: A tensor containing the combined weights for
#             all variables.
#     """
#     # Load weights for U, V, T, Q
#     varname_upper_air = conf["data"]["variables"]
#     varname_surface = conf["data"]["surface_variables"]
#     varname_diagnostics = conf["data"]["diagnostic_variables"]
# 
#     # surface + diag channels
#     N_channels_single = len(varname_surface) + len(varname_diagnostics)
# 
#     weights_upper_air = torch.tensor(
#         [conf["loss"]["variable_weights"][var] for var in varname_upper_air]
#     ).view(1, channels * frames, 1, 1)
# 
#     weights_single = torch.tensor(
#         [
#             conf["loss"]["variable_weights"][var]
#             for var in (varname_surface + varname_diagnostics)
#         ]
#     ).view(1, N_channels_single, 1, 1)
# 
#     # Combine all weights along the color channel
#     var_weights = torch.cat([weights_upper_air, weights_single], dim=1)
# 
#     return var_weights


class DownscalingLoss(torch.nn.Module):
    """Custom loss function for downscaling.  Combines base loss with
    optional spectral and power loss components.  Loss funciton can
    incorporate variable-specific weights.

    Args:
        conf (dict): configuration dictionary containing loss function
            settings and weights.
        tnames (list): a list of the names of the variables corresponding
            to the channels in the output tensor generated by the model.
            Variable names are `dataset.variable[.zvalue]`.  This list
            comes from a DownscalingDataset.tnames variable.
        validation (bool, optional): whether loss function is in validation
            mode.  Defaults to False.
    """

    def __init__(self, conf, tindex, validation=False):
        super(DownscalingLoss, self).__init__()

        # todo: make this a dataclass, initialize with **conf['loss']

        # todo: move this to parser
        if 'use_latitude_weights' in conf['loss']:
            warnings.warn("latitude weights not applicable to downscaling")
        
        for stub in ['use_variable_weights', 'use_power_loss',
                     'use_spectral_loss',]:
            if stub in conf['loss']:
                warnings.warn(f"{stub} not yet implemented for downscaling")
        
        self.training_loss = conf['loss']['training_loss']

        # change to fft_loss = None / 'psd' / '2d'] (radiobutton not checkbox)
        self.use_power_loss = conf['loss']['use_power_loss']
        self.use_spectral_loss = conf['loss']['use_spectral_loss']
        self.spectral_lambda_reg = conf['loss']['spectral_lambda_reg']
        self.spectral_wavenum_init = conf['loss']['spectral_wavenum_init']

        # # setup frequency-domain loss functions here:
        # self.power_loss = PSDLoss(wavenum_init)
        # self.spectral_loss = SpectralLoss2D(wavenum_init, reduction="none")
        
        self.use_variable_weights = conf['loss']['use_variable_weights']
        if self.use_variable_weights:
            pass
            # construct tensor self.var_weights:
            # check that we have weights for everything in tindex
            # warn and/or set default values if not
            # create np.array from list of weights (tindex order)
            # convert to tensor using torch.from_numpy
            # self.var_weights = weights tensor
        
        # see docstring for description
        self.tindex = tindex
                
        self.validation = validation

        if self.validation and not self.training_loss == "KCRPS":
            self.loss_fn = nn.L1Loss(reduction="none")
        else:
            self.loss_fn = load_loss(self.training_loss, reduction="none")
        
    

    def forward(self, target, pred):
        """Calculate the total loss for the given target and prediction.

        This method computes the base loss between the target and
        prediction, applies optional variable weights, and optionally
        adds spectral and power loss components.

        Args:
            target (torch.Tensor): Ground truth tensor.
            pred (torch.Tensor): Predicted tensor.

        Returns:
            torch.Tensor: The computed loss value.
        """

        loss = self.loss_fn(target, pred)

        # if var weights:
        #   loop on vars / channels
        
        loss = torch.mean(loss)

        if self.validation:
            if self.use_spectral_loss:
                loss += (self.spectral_lambda_reg *
                         self.spectral_loss_fn(target, pred))
        else:
            if self.use_power_loss:
                loss += (self.power_lambda_reg *
                         self.power_loss_fn(target, pred)).mean()

        return loss
