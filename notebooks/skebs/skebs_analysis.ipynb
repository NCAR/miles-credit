{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import logging\n",
    "from credit.models import load_model\n",
    "import yaml\n",
    "import os\n",
    "import xarray as xr\n",
    "from os.path import join\n",
    "# from credit.models.skebs_model import SKEBS\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_dir = \"/glade/derecho/scratch/dkimpara/CREDIT_runs/skebs_fcnn_scaled_train\"\n",
    "orig_ckpt = torch.load(join(model_dir, \"checkpoint.pt\"), map_location=\"cpu\")\n",
    "state_dict = orig_ckpt['model_state_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_loc = \"/glade/work/dkimpara/CREDIT_runs/skebs_1dg_cesm/\"\n",
    "# config = \"/glade/work/dkimpara/CREDIT_runs/skebs_1dg_cesm_frozen/model.yml\"\n",
    "config = \"/glade/work/dkimpara/CREDIT_runs/skebs_1dg_cesm_tuning/model.yml\"\n",
    "with open(config) as cf:\n",
    "    conf = yaml.load(cf, Loader=yaml.FullLoader)\n",
    "save_loc = os.path.expandvars(conf[\"save_loc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load(join(save_loc, \"checkpoint.pt\"),  map_location=torch.device('cpu'))\n",
    "state_dict = ckpt[\"model_state_dict\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postblock_keys = [key for key in state_dict.keys() if 'postblock' in key]\n",
    "print(postblock_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectral_filter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "berner_values = [0.125, 0.083, -1.27, 10e-4, 0.1]\n",
    "for i, key in enumerate(postblock_keys[:-2]):\n",
    "    print(f'{key}: {state_dict[key]:.3f} | Berner value: {berner_values[i]}')\n",
    "\n",
    "min_backscatter, max_backscatter = state_dict[postblock_keys[-1]].min(), state_dict[postblock_keys[-1]].max()\n",
    "print(f\"min backscatter: {min_backscatter:.3f}, max backscatter {max_backscatter:.3f}\")\n",
    "\n",
    "spectral_filter = state_dict[postblock_keys[-2]].squeeze()\n",
    "plt.plot(range(len(spectral_filter)), spectral_filter)\n",
    "plt.title(\"spectral filter coefficients\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_keys = len(state_dict.keys()) - len(postblock_keys)\n",
    "\n",
    "base_model_keys = [key for key in state_dict.keys() if 'postblock' not in key]\n",
    "\n",
    "num_close = 0\n",
    "for key in base_model_keys:\n",
    "    num_close += 1 if torch.allclose(o_state_dict[key], state_dict[key], atol=1e-2) else 0\n",
    "print(num_close/num_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in postblock_keys:\n",
    "    print(key, state_dict[key])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def remove_nan_rows(df):\n",
    "    \"\"\"\n",
    "    Removes rows from the DataFrame that contain any NaN values.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: The DataFrame with rows containing NaN values removed.\n",
    "    \"\"\"\n",
    "    return df.dropna()\n",
    "\n",
    "train_log2 = pd.read_csv(join(save_loc, 'training_log.csv'))\n",
    "train_log2 = remove_nan_rows(train_log2)\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "for col in ['train_loss', 'valid_loss']:\n",
    "    data = train_log2[col]\n",
    "    plt.plot(data, label=col)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "for col in ['train_acc', 'valid_acc']:\n",
    "    data = train_log2[col]\n",
    "    plt.plot(data, label=col)\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:credit]",
   "language": "python",
   "name": "conda-env-credit-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
